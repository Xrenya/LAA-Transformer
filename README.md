# LAA-Transformer
Learning Attention from Attention: Efficient Self-Refinement Transformer for Face Super-Resolution, IJCAI 2023 (PyTorch Code)

Unofficial model reproduction.

**TODO**:
- [ ] Build the model
  - Test replacing `DWT` layer with `F.conv2d(in_channels=in_channels, groups=in_channels)`
- [ ] Training Pipeline
- [ ] Train & test model
